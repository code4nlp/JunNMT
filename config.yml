# Network
encoder_type:
decoder_type: AttnDecoderRNN #InputFeedDecoder, AttnDecoderRNN, ScheduledDecoder
rnn_type: LSTM #RNN, LSTM, GRU
bidirectional: true
embedding_size: 500
hidden_size: 500
num_layers: 2
dropout: 0.3
atten_model: general #general, dot, none
param_init: 0.1

src_max_len: 50
tgt_max_len: 50

src_vocab_size: 30000
tgt_vocab_size: 30000

test_bleu: true
multi_bleu_src: /home/gaojun4ever/Documents/Projects/mt-exp/data/dev/nist02.cn
multi_bleu_refs: # Multiple reference
  - /home/gaojun4ever/Documents/Projects/mt-exp/data/dev/nist02.en0
  - /home/gaojun4ever/Documents/Projects/mt-exp/data/dev/nist02.en1
  - /home/gaojun4ever/Documents/Projects/mt-exp/data/dev/nist02.en2
  - /home/gaojun4ever/Documents/Projects/mt-exp/data/dev/nist02.en3


# Misc
use_cuda: true
random_seed: 3435
# Train
optim_method: adam #adadelta, adam, sgd
max_grad_norm: 5
learning_rate: 0.001
learning_rate_decay: 1
start_decay_at: 8
weight_decay: 0 #  weight decay(L2 penalty)
num_train_epochs: 100
steps_per_stats: 100
steps_per_eval: 1000
batch_size: 64

start_epoch_at: 


# training_method:  scheduled_samping # teacher_forcing, scheduled_samping
ratio_scheduler_type: Linear # Linear, Exponential, InverseSigmoid
teacher_forcing_ratio: 0.5

# Test
replace_unk: true
decode_max_length: 100
beam_size: 3

out_dir: ./out_dir # path to save model
log_dir: ./log_dir # for tensorboard logdir